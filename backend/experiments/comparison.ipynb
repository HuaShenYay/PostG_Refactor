{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐算法对比实验\n",
    "\n",
    "本实验对比三种推荐算法在诗词推荐系统上的表现：\n",
    "\n",
    "1. **Content-Based (CB)** - 基于 TF-IDF 内容相似度\n",
    "2. **Item-Based CF** - 基于评分矩阵的物品协同过滤\n",
    "3. **BERTopic Hybrid** - 你的系统 (语义向量 + User-CF + Item-CF)\n",
    "\n",
    "## 评估指标\n",
    "- MAE (平均绝对误差)\n",
    "- Precision@K (准确率)\n",
    "- Recall@K (召回率)\n",
    "- F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# 设置工作目录和路径\n",
    "notebook_dir = os.path.dirname(os.path.abspath('comparison.ipynb'))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "from backend.core.content_recommender import ContentBasedRecommender\n",
    "from backend.core.collaborative_filter import ItemBasedCFRecommender\n",
    "from backend.core.bertopic_recommender import BertopicRecommender\n",
    "\n",
    "print(\"依赖加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulation_data(n_users=50, n_poems=100, n_ratings_per_user=15):\n",
    "    \"\"\"生成模拟的诗词评分数据\"\"\"\n",
    "    \n",
    "    poems = []\n",
    "    poem_contents = [\n",
    "        \"明月几时有把酒问青天\",\n",
    "        \"床前明月光疑是地上霜\",\n",
    "        \"春风又绿江南岸明月何时照我还\",\n",
    "        \"大漠孤烟直长河落日圆\",\n",
    "        \"会当凌绝顶一览众山小\",\n",
    "        \"海内存知己天涯若比邻\",\n",
    "        \"落红不是无情物化作春泥更护花\",\n",
    "        \"春蚕到死丝方尽蜡炬成灰泪始干\",\n",
    "        \"山重水复疑无路柳暗花明又一村\",\n",
    "        \"欲穷千里目更上一层楼\"\n",
    "    ]\n",
    "    \n",
    "    for i in range(n_poems):\n",
    "        poems.append({\n",
    "            'id': i,\n",
    "            'title': f'诗词{i}',\n",
    "            'content': poem_contents[i % len(poem_contents)] + f' 诗云作品第{i}首'\n",
    "        })\n",
    "    \n",
    "    users = [{'id': i, 'username': f'user_{i}'} for i in range(n_users)]\n",
    "    \n",
    "    interactions = []\n",
    "    \n",
    "    user_preferences = [\n",
    "        [0, 1, 2, 10, 11, 20, 21],\n",
    "        [3, 4, 9, 12, 30, 31],\n",
    "        [5, 6, 7, 8, 13, 14, 40, 41],\n",
    "    ]\n",
    "    \n",
    "    for user_idx in range(n_users):\n",
    "        pref_group = user_preferences[user_idx % len(user_preferences)]\n",
    "        \n",
    "        rated_items = random.sample(range(n_poems), min(n_ratings_per_user, n_poems))\n",
    "        for item_idx in rated_items:\n",
    "            base_rating = 3.0\n",
    "            if item_idx % len(poem_contents) in pref_group:\n",
    "                base_rating = 4.5\n",
    "            \n",
    "            rating = np.clip(base_rating + random.uniform(-1, 1), 1.0, 5.0)\n",
    "            interactions.append({\n",
    "                'user_id': user_idx,\n",
    "                'poem_id': item_idx,\n",
    "                'rating': round(rating, 1),\n",
    "                'liked': rating >= 4.0\n",
    "            })\n",
    "    \n",
    "    print(f\"生成数据:\")\n",
    "    print(f\"  用户数: {n_users}\")\n",
    "    print(f\"  诗歌数: {n_poems}\")\n",
    "    print(f\"  评分数: {len(interactions)}\")\n",
    "    \n",
    "    return users, poems, interactions\n",
    "\n",
    "users, poems, all_interactions = generate_simulation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(interactions, test_ratio=0.2):\n",
    "    \"\"\"划分训练集和测试集\"\"\"\n",
    "    train_interactions = []\n",
    "    test_interactions = []\n",
    "    \n",
    "    user_interactions = defaultdict(list)\n",
    "    for inter in interactions:\n",
    "        user_interactions[inter['user_id']].append(inter)\n",
    "    \n",
    "    for user_id, user_inters in user_interactions.items():\n",
    "        n = len(user_inters)\n",
    "        test_size = max(1, int(n * test_ratio))\n",
    "        \n",
    "        indices = list(range(n))\n",
    "        random.shuffle(indices)\n",
    "        test_indices = indices[:test_size]\n",
    "        train_indices = indices[test_size:]\n",
    "        \n",
    "        for i in train_indices:\n",
    "            train_interactions.append(user_inters[i])\n",
    "        for i in test_indices:\n",
    "            test_interactions.append(user_inters[i])\n",
    "    \n",
    "    return train_interactions, test_interactions\n",
    "\n",
    "train_interactions, test_interactions = split_train_test(all_interactions)\n",
    "\n",
    "print(f\"训练集大小: {len(train_interactions)}\")\n",
    "print(f\"测试集大小: {len(test_interactions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"训练 Content-Based 模型...\")\n",
    "cb_recommender = ContentBasedRecommender()\n",
    "cb_recommender.fit(poems)\n",
    "\n",
    "print(\"\\n训练 Item-CF 模型...\")\n",
    "item_cf_recommender = ItemBasedCFRecommender()\n",
    "poem_ids = [p['id'] for p in poems]\n",
    "item_cf_recommender.fit(train_interactions, poem_ids)\n",
    "\n",
    "print(\"\\n训练 BERTopic 模型...\")\n",
    "bertopic_recommender = BertopicRecommender()\n",
    "bertopic_recommender.fit(poems, train_interactions)\n",
    "\n",
    "print(\"\\n所有模型训练完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(recommender, train_interactions, test_interactions, poems, top_k=10, threshold=4.0):\n    \"\"\"计算评估指标\"\"\"\n    \n    user_test_data = defaultdict(list)\n    for inter in test_interactions:\n        user_test_data[inter['user_id']].append(inter)\n    \n    user_train_data = defaultdict(list)\n    for inter in train_interactions:\n        user_train_data[inter['user_id']].append(inter)\n    \n    total_mae = []\n    total_precision = []\n    total_recall = []\n    total_f1 = []\n    \n    poem_id_to_idx = {p['id']: i for i, p in enumerate(poems)}\n    \n    # 判断推荐器类型\n    is_bertopic = hasattr(recommender, 'bertopic_model')\n    is_content_based = type(recommender).__name__ == 'ContentBasedRecommender'\n    is_item_cf = type(recommender).__name__ == 'ItemBasedCFRecommender'\n    \n    for user_id, test_items in user_test_data.items():\n        train_items = user_train_data.get(user_id, [])\n        \n        if not train_items:\n            continue\n        \n        relevant_items = set(i['poem_id'] for i in test_items if i['rating'] >= threshold)\n        \n        if len(relevant_items) == 0:\n            continue\n        \n        exclude_ids = set(i['poem_id'] for i in train_items)\n        exclude_ids.update(set(i['poem_id'] for i in test_items))\n        \n        # 根据推荐器类型调用正确的API\n        user_profile = None\n        try:\n            if is_bertopic:\n                # BERTopic: recommend(user_interactions, all_interactions, top_k)\n                recs = recommender.recommend(train_items, train_interactions, top_k)\n            elif is_content_based:\n                # Content-Based: 需要先构建用户画像\n                rated_poems = []\n                ratings = []\n                for item in train_items:\n                    poem_id = item['poem_id']\n                    if poem_id in poem_id_to_idx:\n                        poem = poems[poem_id_to_idx[poem_id]]\n                        rated_poems.append(poem)\n                        ratings.append(item['rating'])\n                \n                if rated_poems:\n                    user_profile = recommender.get_user_profile(rated_poems, ratings)\n                    recs = recommender.recommend(user_profile, exclude_ids, top_k)\n                else:\n                    recs = []\n            elif is_item_cf:\n                # Item-CF: recommend(user_interactions, exclude_ids, top_k)\n                recs = recommender.recommend(train_items, exclude_ids, top_k)\n            else:\n                recs = []\n        except Exception as e:\n            print(f\"  推荐异常: {e}\")\n            recs = []\n        \n        recommended_items = set(r['poem_id'] for r in recs) if recs else set()\n        \n        tp = len(recommended_items & relevant_items)\n        fp = len(recommended_items - relevant_items)\n        fn = len(relevant_items - recommended_items)\n        \n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n        \n        total_precision.append(precision)\n        total_recall.append(recall)\n        total_f1.append(f1)\n        \n        # 预测评分计算MAE\n        for test_item in test_items:\n            try:\n                if is_bertopic:\n                    pred = recommender.predict_rating(train_items, test_item['poem_id'])\n                elif is_content_based:\n                    if user_profile is not None:\n                        poem_idx = poem_id_to_idx.get(test_item['poem_id'])\n                        if poem_idx is not None:\n                            pred = recommender.predict_rating(user_profile, poem_idx)\n                        else:\n                            pred = 3.0\n                    else:\n                        pred = 3.0\n                elif is_item_cf:\n                    pred = recommender.predict_rating(train_items, test_item['poem_id'])\n                else:\n                    pred = 3.0\n                    \n                total_mae.append(abs(pred - test_item['rating']))\n            except Exception as e:\n                pass\n    \n    return {\n        'mae': np.mean(total_mae) if total_mae else 0,\n        'precision': np.mean(total_precision) if total_precision else 0,\n        'recall': np.mean(total_recall) if total_recall else 0,\n        'f1': np.mean(total_f1) if total_f1 else 0\n    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 运行实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"开始评估...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top_k = 10\n",
    "threshold = 4.0\n",
    "\n",
    "print(\"\\n[1] Content-Based 评估...\")\n",
    "cb_metrics = calculate_metrics(cb_recommender, train_interactions, test_interactions, poems, top_k, threshold)\n",
    "\n",
    "print(\"[2] Item-CF 评估...\")\n",
    "item_cf_metrics = calculate_metrics(item_cf_recommender, train_interactions, test_interactions, poems, top_k, threshold)\n",
    "\n",
    "print(\"[3] BERTopic Hybrid 评估...\")\n",
    "bertopic_metrics = calculate_metrics(bertopic_recommender, train_interactions, test_interactions, poems, top_k, threshold)\n",
    "\n",
    "print(\"\\n评估完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 结果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = {\n",
    "    'Content-Based': cb_metrics,\n",
    "    'Item-CF': item_cf_metrics,\n",
    "    'BERTopic Hybrid': bertopic_metrics\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"实验结果对比\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'算法':<20} {'MAE':<10} {'Precision':<12} {'Recall':<10} {'F1':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name:<20} {metrics['mae']:<10.4f} {metrics['precision']:<12.4f} {metrics['recall']:<10.4f} {metrics['f1']:<10.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"结论: BERTopic Hybrid 在各指标上的表现\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cb_mae = cb_metrics['mae']\n",
    "item_cf_mae = item_cf_metrics['mae']\n",
    "bertopic_mae = bertopic_metrics['mae']\n",
    "\n",
    "if bertopic_mae < cb_mae and bertopic_mae < item_cf_mae:\n",
    "    print(f\"✓ MAE: BERTopic Hybrid 最优 ({bertopic_mae:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ MAE: BERTopic Hybrid 为 {bertopic_mae:.4f}\")\n",
    "\n",
    "if bertopic_metrics['precision'] >= cb_metrics['precision'] and bertopic_metrics['precision'] >= item_cf_metrics['precision']:\n",
    "    print(f\"✓ Precision: BERTopic Hybrid 最优 ({bertopic_metrics['precision']:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ Precision: BERTopic Hybrid 为 {bertopic_metrics['precision']:.4f}\")\n",
    "\n",
    "if bertopic_metrics['recall'] >= cb_metrics['recall'] and bertopic_metrics['recall'] >= item_cf_metrics['recall']:\n",
    "    print(f\"✓ Recall: BERTopic Hybrid 最优 ({bertopic_metrics['recall']:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ Recall: BERTopic Hybrid 为 {bertopic_metrics['recall']:.4f}\")\n",
    "\n",
    "if bertopic_metrics['f1'] >= cb_metrics['f1'] and bertopic_metrics['f1'] >= item_cf_metrics['f1']:\n",
    "    print(f\"✓ F1: BERTopic Hybrid 最优 ({bertopic_metrics['f1']:.4f})\")\n",
    "else:\n",
    "    print(f\"✗ F1: BERTopic Hybrid 为 {bertopic_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "metrics_names = ['mae', 'precision', 'recall', 'f1']\n",
    "titles = ['MAE (越低越好)', 'Precision@K', 'Recall@K', 'F1-Score']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics_names, titles)):\n",
    "    ax = axes[idx]\n",
    "    values = [results['Content-Based'][metric], results['Item-CF'][metric], results['BERTopic Hybrid'][metric]]\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    \n",
    "    bars = ax.bar(['CB', 'Item-CF', 'BERTopic'], values, color=colors)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Score')\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('experiment_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n图表已保存至 experiment_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 总结\n",
    "\n",
    "本实验对比了三种推荐算法：\n",
    "\n",
    "1. **Content-Based (CB)**: 基于 TF-IDF 特征的内容推荐\n",
    "   - 优点: 冷启动问题小，不需要其他用户数据\n",
    "   - 缺点: 只能推荐与历史相似的物品，难以发现新兴趣\n",
    "\n",
    "2. **Item-Based CF**: 基于评分矩阵的物品协同过滤\n",
    "   - 优点: 可以发现用户的潜在兴趣\n",
    "   - 缺点: 冷启动问题严重，新物品难以被推荐\n",
    "\n",
    "3. **BERTopic Hybrid**: 混合推荐系统\n",
    "   - 结合语义向量 (BERTopic)\n",
    "   - 用户协同过滤 (User-CF)\n",
    "   - 物品协同过滤 (Item-CF)\n",
    "   - 根据用户活跃度动态调整权重\n",
    "   - **优势**: 兼顾内容相似性和用户行为相似性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}